# üîß Solu√ß√£o para Yahoo Finance no Docker

## üéØ Problema Identificado

O Yahoo Finance funciona perfeitamente na sua m√°quina local, mas falha dentro do Docker com erro **HTTP 429 (Too Many Requests)**.

### Por que isso acontece?

- **Localmente**: Sua m√°quina tem IP residencial, User-Agent normal, hist√≥rico de navega√ß√£o
- **No Docker**: Container tem IP diferente, sem cookies, detectado como "bot" pelo Yahoo Finance
- **Resultado**: Yahoo Finance bloqueia requisi√ß√µes do Docker (rate limiting agressivo)

## ‚úÖ Solu√ß√£o Recomendada: Pipeline Local + Docker para Servir

Execute o pipeline de dados **localmente** (onde Yahoo Finance funciona) e use o Docker apenas para servir a aplica√ß√£o.

### Passo a Passo

#### 1. Executar Pipeline Localmente

```bash
# Certifique-se que o PostgreSQL est√° rodando no Docker
docker-compose up -d postgres

# Execute o pipeline na sua m√°quina local
python -m scripts.run_pipeline
```

O pipeline vai:
- ‚úÖ Buscar dados do Yahoo Finance (funciona local!)
- ‚úÖ Salvar no PostgreSQL (que est√° no Docker)
- ‚úÖ Calcular features e scores
- ‚úÖ Gerar rankings

#### 2. Iniciar Backend e Frontend no Docker

```bash
# Iniciar apenas backend e frontend (postgres j√° est√° rodando)
docker-compose up -d backend frontend
```

Agora o Docker vai:
- ‚úÖ Ler dados do PostgreSQL (j√° populado pelo pipeline local)
- ‚úÖ Servir a API
- ‚úÖ Exibir o frontend

### Vantagens desta Abordagem

1. **Yahoo Finance funciona** - Pipeline roda localmente onde n√£o h√° bloqueio
2. **Docker serve a aplica√ß√£o** - Backend e Frontend em containers
3. **Dados persistentes** - PostgreSQL mant√©m os dados entre execu√ß√µes
4. **Flexibilidade** - Voc√™ controla quando atualizar os dados

---

## üîÑ Workflow Recomendado

### Primeira Execu√ß√£o (Setup Inicial)

```bash
# 1. Subir PostgreSQL
docker-compose up -d postgres

# 2. Aguardar PostgreSQL ficar pronto (10-15 segundos)
timeout /t 15

# 3. Executar pipeline localmente
python -m scripts.run_pipeline

# 4. Subir backend e frontend
docker-compose up -d backend frontend

# 5. Acessar aplica√ß√£o
start http://localhost:8501
```

### Atualiza√ß√µes Di√°rias de Dados

```bash
# Executar pipeline para atualizar dados
python -m scripts.run_pipeline

# Reiniciar backend para garantir cache limpo (opcional)
docker-compose restart backend
```

### Parar Tudo

```bash
docker-compose down
```

---

## üìù Script Automatizado

Criei um script `run_local_pipeline.bat` para facilitar:

```batch
@echo off
echo ========================================
echo PIPELINE LOCAL + DOCKER
echo ========================================
echo.

echo [1/4] Verificando PostgreSQL...
docker-compose up -d postgres
timeout /t 15 /nobreak

echo.
echo [2/4] Executando pipeline local...
python -m scripts.run_pipeline

echo.
echo [3/4] Iniciando backend e frontend...
docker-compose up -d backend frontend

echo.
echo [4/4] Aguardando containers ficarem prontos...
timeout /t 20 /nobreak

echo.
echo ========================================
echo PRONTO!
echo ========================================
echo.
echo Acesse: http://localhost:8501
echo API Docs: http://localhost:8000/docs
echo.
pause
```

---

## üéØ Alternativas (Caso queira tudo no Docker)

### Op√ß√£o 1: Usar API Alternativa

Substituir Yahoo Finance por outra API que n√£o tenha rate limiting t√£o agressivo:

- **Alpha Vantage** - 5 requisi√ß√µes/minuto (gr√°tis)
- **IEX Cloud** - 50k requisi√ß√µes/m√™s (gr√°tis)
- **Twelve Data** - 800 requisi√ß√µes/dia (gr√°tis)

### Op√ß√£o 2: Proxy/VPN no Docker

Configurar um proxy ou VPN dentro do container para mascarar o IP:

```yaml
backend:
  environment:
    HTTP_PROXY: http://seu-proxy:porta
    HTTPS_PROXY: http://seu-proxy:porta
```

### Op√ß√£o 3: Cache de Dados

Implementar cache local dos dados do Yahoo Finance:

- Buscar dados 1x por dia
- Armazenar em arquivo local
- Reutilizar durante o dia

---

## ‚úÖ Conclus√£o

A solu√ß√£o **Pipeline Local + Docker para Servir** √© a mais simples e eficaz:

- ‚úÖ Yahoo Finance funciona (local)
- ‚úÖ Aplica√ß√£o em Docker (f√°cil deploy)
- ‚úÖ Dados persistentes (PostgreSQL)
- ‚úÖ Sem custos adicionais
- ‚úÖ Sem complexidade extra

**Recomenda√ß√£o**: Use esta abordagem e execute o pipeline localmente 1x por dia (ou quando quiser atualizar os dados).
